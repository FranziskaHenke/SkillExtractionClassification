{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20861874\n",
      "0\n",
      "skipgram, punctuation_marks, stoppwords, multiword, lower_case, vector_dim True False False False False 100\n",
      "init /home/franzi/Documents/models/no_pm_no_sw_vecDim100/skip_gram_model.model\n",
      "loading existing w2v model from  /home/franzi/Documents/models/no_pm_no_sw_vecDim100/skip_gram_model.model\n",
      "using data from  /home/franzi/Documents/data/data_bg_pos_wFeatures_4_vecDim100\n",
      "loading data...\n",
      "37823 37823 12053 12053 0 0\n",
      "took:  4.172369003295898\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/home/franzi/anzeigendaten/python_base/skillextraktion/fh_ma')\n",
    "sys.path.append('/home/franzi/anzeigendaten/EnvPython')\n",
    "import prepare_training_data\n",
    "from labels import *\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "start = time.time()\n",
    "x_train, y_train, x_test, y_test, test_afks, features = prepare_training_data.get_training_data(berufsgruppen=True, pos=True, word_features=True)\n",
    "print('took: ',time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         1.         0.\n",
      "  0.         0.         1.         0.         1.         0.00033559]]\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i,f in enumerate(features):\n",
    "    features[i] = np.array(f)\n",
    "pos_test, wf_test, bg_test, pos_train, wf_train, bg_train,  _, _, _ = features\n",
    "\n",
    "print(wf_train[0]) # Abgeschlossene\n",
    "print(pos_train[0]) # ADJA first\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_test = np.reshape(wf_test, (wf_test.shape[0], wf_test.shape[2]))\n",
    "wf_train = np.reshape(wf_train, (wf_train.shape[0], wf_train.shape[2]))\n",
    "pos_test = np.reshape(pos_test, (pos_test.shape[0], pos_test.shape[2]))\n",
    "pos_train = np.reshape(pos_train, (pos_train.shape[0], pos_train.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-20 12:40:34 WARNING: From /home/franzi/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "12053/12053 [==============================] - 26s 2ms/sample - loss: 2.0945 - acc: 0.0233\n",
      "Train on 37823 samples, validate on 12053 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-20 12:41:04 WARNING: From /home/franzi/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "37823/37823 [==============================] - 214s 6ms/sample - loss: 0.7689 - acc: 0.7217 - val_loss: 0.6577 - val_acc: 0.7630\n",
      "Epoch 2/5\n",
      "37823/37823 [==============================] - 209s 6ms/sample - loss: 0.5898 - acc: 0.7857 - val_loss: 0.5093 - val_acc: 0.8176\n",
      "Epoch 3/5\n",
      "37823/37823 [==============================] - 209s 6ms/sample - loss: 0.4781 - acc: 0.8305 - val_loss: 0.4553 - val_acc: 0.8386\n",
      "Epoch 4/5\n",
      "37823/37823 [==============================] - 206s 5ms/sample - loss: 0.4304 - acc: 0.8506 - val_loss: 0.4357 - val_acc: 0.8513\n",
      "Epoch 5/5\n",
      "37823/37823 [==============================] - 211s 6ms/sample - loss: 0.4056 - acc: 0.8573 - val_loss: 0.4669 - val_acc: 0.8382\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "print('Build model...')\n",
    "\n",
    "vector_window_input = layers.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "vw = layers.LSTM(256, return_sequences=True)(vector_window_input)\n",
    "vw = layers.Dropout(0.5)(vw)\n",
    "vw = layers.BatchNormalization()(vw)\n",
    "vw = layers.LSTM(512, return_sequences=True)(vw)\n",
    "vw = layers.Dropout(0.5)(vw)\n",
    "vw = layers.BatchNormalization()(vw)\n",
    "vw = layers.LSTM(512)(vw)\n",
    "vw = layers.Dropout(0.5)(vw)\n",
    "vw = layers.BatchNormalization()(vw)\n",
    "vw = layers.Dense(128, activation='relu')(vw)\n",
    "\n",
    "wf_input = layers.Input(shape=(len(wf_train[0])))\n",
    "f = layers.Dense(512, activation='relu')(wf_input)\n",
    "f = layers.Dropout(0.5)(f)\n",
    "f = layers.Dense(256, activation='relu')(f)\n",
    "\n",
    "pos_input = layers.Input(shape=(len(pos_train[0])))\n",
    "p = layers.Dense(512, activation='relu')(pos_input)\n",
    "p = layers.Dropout(0.5)(p)\n",
    "p = layers.Dense(256, activation='relu')(p)\n",
    "\n",
    "bg_input = layers.Input(shape=(len(bg_train[0])))\n",
    "b = layers.Dense(512, activation='relu')(bg_input)\n",
    "b = layers.Dropout(0.5)(b)\n",
    "b = layers.Dense(256, activation='relu')(b)\n",
    "\n",
    "x = layers.concatenate([vw, f, p, b])\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "out = layers.Dense(units=len(labels), activation='softmax')(x)\n",
    "all_model = models.Model(inputs=[vector_window_input, wf_input, pos_input, bg_input], outputs=[out])\n",
    "\n",
    "all_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "all_model.evaluate(x=[x_test, wf_test, pos_test, bg_test], y=y_test)\n",
    "\n",
    "batch_size=32\n",
    "history = all_model.fit([x_train, wf_train, pos_train, bg_train], y_train, batch_size=batch_size, shuffle=True, epochs=5, validation_data=([x_test, wf_test, pos_test, bg_test], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(np.arange(1, len(history.history['acc'])+1), history.history['acc'])\n",
    "plt.plot(np.arange(1, len(history.history['acc'])+1), history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(np.arange(1, len(history.history['acc'])+1))\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test data\n",
    "all_y_pred = all_model.predict([x_test, wf_test, pos_test, bg_test])\n",
    "all_pred_label = prepare_training_data.one_hot_to_labels(all_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# convert one hot to labels for test data\n",
    "true_label = prepare_training_data.one_hot_to_labels(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train on 37823 samples, validate on 12053 samples\n",
      "Epoch 1/5\n",
      "37823/37823 [==============================] - 158s 4ms/sample - loss: 0.8396 - acc: 0.6886 - val_loss: 0.6484 - val_acc: 0.7629\n",
      "Epoch 2/5\n",
      "37823/37823 [==============================] - 144s 4ms/sample - loss: 0.5310 - acc: 0.8101 - val_loss: 0.4882 - val_acc: 0.8241\n",
      "Epoch 3/5\n",
      "37823/37823 [==============================] - 137s 4ms/sample - loss: 0.4683 - acc: 0.8380 - val_loss: 0.4668 - val_acc: 0.8451\n",
      "Epoch 4/5\n",
      "37823/37823 [==============================] - 136s 4ms/sample - loss: 0.4279 - acc: 0.8516 - val_loss: 0.4250 - val_acc: 0.8470\n",
      "Epoch 5/5\n",
      "37823/37823 [==============================] - 136s 4ms/sample - loss: 0.3993 - acc: 0.8624 - val_loss: 0.4555 - val_acc: 0.8455\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "print('Build model...')\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(layers.LSTM(256, return_sequences=True, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
    "lstm_model.add(layers.BatchNormalization())\n",
    "lstm_model.add(layers.Dropout(0.5))\n",
    "lstm_model.add(layers.LSTM(512, return_sequences=True))\n",
    "lstm_model.add(layers.Dropout(0.5))\n",
    "lstm_model.add(layers.BatchNormalization())\n",
    "lstm_model.add(layers.LSTM(256))\n",
    "lstm_model.add(layers.Dropout(0.5))\n",
    "lstm_model.add(layers.Dense(256))\n",
    "lstm_model.add(layers.Dense(units=len(labels)))\n",
    "lstm_model.add(layers.Activation('softmax'))\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "batch_size=32\n",
    "history = lstm_model.fit(x_train, y_train, batch_size=batch_size, shuffle=True, epochs=5, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predict test data\n",
    "lstm_y_pred = lstm_model.predict([x_test])\n",
    "lstm_pred_label = prepare_training_data.one_hot_to_labels(lstm_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "12053/12053 [==============================] - 26s 2ms/sample - loss: 2.0737 - acc: 0.0975\n",
      "Train on 37823 samples, validate on 12053 samples\n",
      "Epoch 1/5\n",
      "37823/37823 [==============================] - 206s 5ms/sample - loss: 0.8005 - acc: 0.7101 - val_loss: 0.7415 - val_acc: 0.7367\n",
      "Epoch 2/5\n",
      "37823/37823 [==============================] - 202s 5ms/sample - loss: 0.5990 - acc: 0.7821 - val_loss: 0.5914 - val_acc: 0.7985\n",
      "Epoch 3/5\n",
      "37823/37823 [==============================] - 200s 5ms/sample - loss: 0.4952 - acc: 0.8227 - val_loss: 0.5394 - val_acc: 0.8197\n",
      "Epoch 4/5\n",
      "37823/37823 [==============================] - 209s 6ms/sample - loss: 0.4466 - acc: 0.8445 - val_loss: 0.4574 - val_acc: 0.8476\n",
      "Epoch 5/5\n",
      "37823/37823 [==============================] - 211s 6ms/sample - loss: 0.4184 - acc: 0.8553 - val_loss: 0.4629 - val_acc: 0.8390\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "print('Build model...')\n",
    "\n",
    "vector_window_input = layers.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "vw = layers.LSTM(256, return_sequences=True)(vector_window_input)\n",
    "vw = layers.Dropout(0.5)(vw)\n",
    "vw = layers.BatchNormalization()(vw)\n",
    "vw = layers.LSTM(512, return_sequences=True)(vw)\n",
    "vw = layers.Dropout(0.5)(vw)\n",
    "vw = layers.BatchNormalization()(vw)\n",
    "vw = layers.LSTM(512)(vw)\n",
    "vw = layers.Dropout(0.5)(vw)\n",
    "vw = layers.BatchNormalization()(vw)\n",
    "vw = layers.Dense(128, activation='relu')(vw)\n",
    "\n",
    "wf_input = layers.Input(shape=(len(wf_train[0])))\n",
    "f = layers.Dense(512, activation='relu')(wf_input)\n",
    "f = layers.Dropout(0.5)(f)\n",
    "f = layers.Dense(256, activation='relu')(f)\n",
    "\n",
    "x = layers.concatenate([vw, f])\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "out = layers.Dense(units=len(labels), activation='softmax')(x)\n",
    "wf_model = models.Model(inputs=[vector_window_input, wf_input], outputs=[out])\n",
    "\n",
    "wf_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "wf_model.evaluate(x=[x_test, wf_test], y=y_test)\n",
    "\n",
    "batch_size=32\n",
    "history = wf_model.fit([x_train, wf_train], y_train, batch_size=batch_size, shuffle=True, epochs=5, validation_data=([x_test, wf_test], y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test data\n",
    "wf_y_pred = wf_model.predict([x_test, wf_test])\n",
    "wf_pred_label = prepare_training_data.one_hot_to_labels(wf_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = []\n",
    "for i in range(len(x_test)):\n",
    "    curr_labels = [lstm_pred_label[i], all_pred_label[i], wf_pred_label[i]]\n",
    "    if(curr_labels.count(lstm_pred_label[i] >= 2)): pred_label.append(lstm_pred_label[i])\n",
    "    elif(curr_labels.count(all_pred_label[i] >= 2)): pred_label.append(all_pred_label[i])\n",
    "    elif(curr_labels.count(wf_pred_label[i] >= 2)): pred_label.append(wf_pred_label[i])\n",
    "    else: pred_label.append(wf_pred_label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|           |   Ausbildung |    Beruf |   allgemein |   berufsspez |   Sprache |   Technologie |   Softskill |   noSkill |\n",
      "|-----------+--------------+----------+-------------+--------------+-----------+---------------+-------------+-----------|\n",
      "| precision |     0.682581 | 0.5      |    0.519337 |     0.646947 |  0.971564 |      0.742038 |    0.699153 |  0.937027 |\n",
      "| recall    |     0.958333 | 0.203125 |    0.263675 |     0.633645 |  0.927602 |      0.901935 |    0.91922  |  0.898958 |\n",
      "| f1        |     0.797287 | 0.288889 |    0.349767 |     0.640227 |  0.949074 |      0.814211 |    0.794224 |  0.917598 |\n",
      "f1 average:  0.6939095950606413\n",
      "f1 average:  0.6141007888329725\n",
      "Precision average:  0.7123307910089202\n",
      "recall average:  0.7133116347633474\n",
      "acc 0.8393760889405127\n"
     ]
    }
   ],
   "source": [
    "# Calc metrics for test data\n",
    "import sklearn\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from tabulate import tabulate\n",
    "label_list = list(labels.keys())\n",
    "\n",
    "headers = [l for l in label_list ]\n",
    "headers = [' '] + headers\n",
    "\n",
    "table=[['precision'] + list(precision_score(true_label, pred_label, average=None)), \n",
    "       ['recall']+list(recall_score(true_label, pred_label, average=None)), \n",
    "       ['f1']+ list(sklearn.metrics.f1_score(true_label, pred_label, average=None))]\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='orgtbl'))\n",
    "f1 = sklearn.metrics.f1_score(true_label, pred_label, average=None)\n",
    "f1 = np.delete(f1, 4)\n",
    "f1 = np.delete(f1, 6)\n",
    "print('f1 average: ',sum(sklearn.metrics.f1_score(true_label, pred_label, average=None))/len(list(precision_score(true_label, pred_label, average=None))))\n",
    "print('f1 average: ',sum(f1)/6)\n",
    "print('Precision average: ',sum(precision_score(true_label, pred_label, average=None)/8))\n",
    "print('recall average: ',sum(recall_score(true_label, pred_label, average=None)/8))\n",
    "print('acc', sklearn.metrics.accuracy_score(true_label, pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_prob = wf_model.predict([x_test, wf_test])\n",
    "lstm_prob = lstm_model.predict_proba([x_test])\n",
    "all_prob = all_model.predict([x_test, wf_test, pos_test, bg_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label2 = []\n",
    "probabilities = []\n",
    "for i in range(len(x_test)):\n",
    "    probs = [0] * len(labels)\n",
    "    items = [lstm_prob[i], all_prob[i], wf_prob[i]]\n",
    "    stats = {}\n",
    "    for net in range(len(items)):\n",
    "        for index in range(len(items[net])):\n",
    "            probs[index] += items[net][index]\n",
    "    pred_label2.append(probs.index(max(probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|           |   Ausbildung |    Beruf |   allgemein |   berufsspez |   Sprache |   Technologie |   Softskill |   noSkill |\n",
      "|-----------+--------------+----------+-------------+--------------+-----------+---------------+-------------+-----------|\n",
      "| precision |     0.769585 | 0.367347 |    0.602817 |     0.631886 |  0.981221 |      0.777778 |    0.755725 |  0.94144  |\n",
      "| recall    |     0.907609 | 0.28125  |    0.30014  |     0.707477 |  0.945701 |      0.903226 |    0.91922  |  0.916106 |\n",
      "| f1        |     0.832918 | 0.318584 |    0.400749 |     0.667549 |  0.963134 |      0.835821 |    0.829493 |  0.9286   |\n",
      "f1 average:  0.7221058806177479\n",
      "f1 average:  0.6475188873607266\n",
      "Precision average:  0.7284748508243106\n",
      "recall average:  0.7350911072323504\n",
      "acc 0.8573799054177383\n"
     ]
    }
   ],
   "source": [
    "# Calc metrics for test data\n",
    "import sklearn\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from tabulate import tabulate\n",
    "label_list = list(labels.keys())\n",
    "\n",
    "headers = [l for l in label_list ]\n",
    "headers = [' '] + headers\n",
    "\n",
    "table=[['precision'] + list(precision_score(true_label, pred_label2, average=None)), \n",
    "       ['recall']+list(recall_score(true_label, pred_label2, average=None)), \n",
    "       ['f1']+ list(sklearn.metrics.f1_score(true_label, pred_label2, average=None))]\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='orgtbl'))\n",
    "f1 = sklearn.metrics.f1_score(true_label, pred_label2, average=None)\n",
    "f1 = np.delete(f1, 4)\n",
    "f1 = np.delete(f1, 6)\n",
    "print('f1 average: ',sum(sklearn.metrics.f1_score(true_label, pred_label2, average=None))/len(list(precision_score(true_label, pred_label2, average=None))))\n",
    "print('f1 average: ',sum(f1)/6)\n",
    "print('Precision average: ',sum(precision_score(true_label, pred_label2, average=None)/8))\n",
    "print('recall average: ',sum(recall_score(true_label, pred_label2, average=None)/8))\n",
    "print('acc', sklearn.metrics.accuracy_score(true_label, pred_label2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
